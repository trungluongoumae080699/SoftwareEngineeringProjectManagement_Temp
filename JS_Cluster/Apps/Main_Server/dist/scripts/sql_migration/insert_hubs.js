import dotenv from "dotenv";
import { promises as fs } from "fs";
import mysql from "mysql2/promise";
dotenv.config({ path: ".env.admin" });
const script_name = "insert_hubs";
const prerequisite_script = "database_modi_01";
const MIGRATION_NAME = "database_modi_01";
const pool = mysql.createPool({
    host: process.env.DB_MYSQL_HOST,
    port: Number(process.env.DB_MYSQL_PORT) || 3306,
    user: process.env.DB_MYSQL_ADMIN_USER,
    password: process.env.DB_MYSQL_ADMIN_PASS,
    database: process.env.DB_MYSQL_NAME,
    connectionLimit: 10,
    waitForConnections: true,
    queueLimit: 1,
});
/* -------------------------------------------------------------------------- */
/*                         CHECK MIGRATION HAS RUN                             */
/* -------------------------------------------------------------------------- */
async function findScriptByName(name) {
    const [rows] = await pool.query(`SELECT 1 FROM migration WHERE name = ? LIMIT 1`, [name]);
    const exists = Array.isArray(rows) && rows.length > 0;
    console.log(exists
        ? `üìú Migration '${name}' already recorded in 'migration' table.`
        : `üìú Migration '${name}' not found in 'migration' table.`);
    return exists;
}
/* -------------------------------------------------------------------------- */
/*                         BULK INSERT HUBS FROM JSON                          */
/* -------------------------------------------------------------------------- */
export async function insertHubsFromJsonBulk() {
    console.log("üìÇ Reading hubs from src/Assets/hubs.json ...");
    const raw = await fs.readFile("src/Assets/hubs.json", "utf8");
    const hubs = JSON.parse(raw);
    if (!Array.isArray(hubs) || hubs.length === 0) {
        console.log("‚ö†Ô∏è hubs.json is empty or not an array, nothing to insert.");
        return;
    }
    console.log(`üì¶ Loaded ${hubs.length} hubs from hubs.json`);
    // Build bulk INSERT
    const placeholders = hubs.map(() => "(?, ?, ?, ?, ?, ?, ?)").join(", ");
    const sql = `
    INSERT INTO hubs (
      id,
      longitude,
      latitude,
      address,
      last_modification_date,
      deleted,
      created_at
    )
    VALUES ${placeholders}
  `;
    const values = [];
    for (const hub of hubs) {
        values.push(hub.id, hub.longitude, hub.latitude, hub.address, hub.last_modification_date, hub.deleted, new Date(hub.created_at) // TIMESTAMP accepts Date/ISO/Date
        );
    }
    console.log("üöÄ Executing bulk INSERT into 'hubs' table...");
    try {
        const [result] = await pool.query(sql, values);
        console.log("‚úÖ Bulk inserted hubs into 'hubs' table.");
        // console.log(result); // uncomment if you want to inspect affectedRows
    }
    catch (err) {
        console.error("‚ùå Bulk insert failed:", err);
        throw err;
    }
}
/* -------------------------------------------------------------------------- */
/*                                    MAIN                                    */
/* -------------------------------------------------------------------------- */
async function main() {
    try {
        console.log("üîç Checking if required migration has been applied...");
        const ok = await findScriptByName(prerequisite_script);
        const alreadyRun = await findScriptByName(script_name);
        if (!ok) {
            console.log(`‚ö†Ô∏è Must run migration '${prerequisite_script}' BEFORE inserting trips.`);
            return;
        }
        if (alreadyRun) {
            console.log(`Script has already been executed`);
            return;
        }
        await insertHubsFromJsonBulk();
        await pool.query(`INSERT INTO migration (name) VALUES (?);`, [script_name]);
        console.log(`üìú Migration '${script_name}' recorded`);
        console.log("üéâ Done inserting hubs (bulk).");
    }
    catch (err) {
        console.error("‚ùå insertHubsFromJsonBulk main() failed:", err);
    }
    finally {
        await pool.end();
        console.log("üîå Closed MySQL pool.");
        process.exit();
    }
}
main();
